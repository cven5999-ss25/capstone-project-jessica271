---
title: "Data Exploration for Capstone Project"
author:
  - name: "Jessica Maina"
    orcid: "0009-0007-5229-3182"
    email: "Jessica.Maina@colorado.edu"
    affiliation:
      - name: "University of Colorado Boulder"
        department: "Department of Civil, Environmental and Architectural Engineering"
        city: "Boulder"
        state: "CO"
        country: "USA"
date: today
format: html
embed-resources: true
editor: visual
execute: 
  echo: true
  warning: false
editor_options: 
  chunk_output_type: console
---

# Introduction

The **African Development Corridor Database 2022**, compiled by Jessica P.R. Thorn, Ben Mwangi, and Diego Juffe Bignoli, provides a comprehensive geospatial dataset of planned and existing development corridors across Africa, including roads, railways, pipelines, and ports. Published on Dryad in September 2022 and updated in October 2022, the dataset aims to support research on the environmental, social, and economic impacts of infrastructure expansion on biodiversity, ecosystems, and local communities.

# Methods

## Reading the Data

```{r}
library(tidyverse) # Load package

install.packages("janitor")
library(janitor)

library(stringr)

# Read data

my_data <- read_csv(here::here("data/raw/AfricanDevelopmentCorridorDatabase2022.csv"))
```

## Data Exploration Approach

```{r}
glimpse(my_data)

dim(my_data)
```

## Initial Data Tidying

```{r}
corridor_data <- my_data |>
  janitor::clean_names() # clean variable names

corridor_data |>
  mutate(
    launch_year = as.numeric(launch_year)  
  ) # convert character columns to numeric type


corridor_data <- corridor_data |>
  mutate(
    amount_funded_total = str_extract_all(amount_funded_usd_millions_per_donor_type, "\\d+\\.*\\d*") |> 
      lapply(as.numeric) |> 
      sapply(sum, na.rm = TRUE)
  )
# str_extract_all extracts all numbers from the observations in  amount_funded_usd_mllions_per_data columns. The \\d+\\.*\\d* extracts all numbers numbers while skiping the NI. 
# lapply(as.numeric) selects all observations in the list as individuals and convert them to numeric values.
# sapply(sum, na.rm = TRUE) selects all observations in the list as indviduals and sums them up for each project in a country.  


corridor_data <- corridor_data |>
  mutate(
    distance_km_maximum = as.numeric(distance_km_maximum),
    usd_amount_million_maximum = as.numeric(usd_amount_million_maximum),
    launch_year = as.numeric(launch_year)
  )
# Final conversion of variables from character data to numeric data needed for data summary
```

# Results

```{r}
country_corridor_data <- corridor_data |>
  group_by(country) |>
  summarize(
    n_corridors = n(),
    avg_length_km = mean(distance_km_maximum, na.rm = TRUE),
    avg_usd_amount = mean(usd_amount_million_maximum, na.rm = TRUE),
    latest_launch = max(launch_year, na.rm = TRUE),
    total_usd_funded = sum(amount_funded_total, na.rm = TRUE)
  ) # Summary of the corridor data from 185 rows and 25 columns to 39 rows and 6 columns. 

clean_country_corridor_data <- country_corridor_data |>
  filter(
    if_all(everything(), ~ !is.infinite(.) & !is.nan(.))
  ) # Remove all rows with missing and infinity data (Nan & Inf) for better visualization of the summary data. 
# if_all() function refers to all columns in a row while everything() refers to all columns in the country_county_data dataset. 

clean_country_corridor_data |>
  arrange(desc(total_usd_funded)) |>
  knitr::kable(digits = 1, caption = "Countries by Total USD Funded")
# Display a clean table of the data summary
```

## Methods

```{r}
corridor_data <- corridor_data |>
  mutate(
    status = case_when(
      str_to_lower(status) %in% c("completed", "complete") ~ "completed",
      str_to_lower(status) %in% c("under construction", "in progress") ~ "under construction",
      TRUE ~ status
    )
  ) # lower case for all variables 

```

# Conclusions

```{r}
write_csv(corridor_data, here::here("data/processed/AfricanDevelopmentCorridorDatabase2022_tidied.csv"))
```

## Summary of Findings

This data cycle has:

-   Loaded and cleaned the data

-   Explored it with key descriptive statistics

-   Fixed several common data issues (character dates, inconsistent categories, entry errors)

## Questions and Next Steps

Next steps will include:

Analyzing the data in terms of regions or development type

Data visualization
